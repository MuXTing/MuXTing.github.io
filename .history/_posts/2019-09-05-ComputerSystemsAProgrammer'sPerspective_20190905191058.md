---
layout: post
title: "高速缓存"
categories: 计算机经典书系列
tags: 深入理解计算机系统 计算机组成原理 
date: 2019-09-05
author: 孙光林
---

* content
{:toc}

"通过让高速缓存里存放可能经常访问的数据， 大部分的内存操作都能在快速的高速缓存中完成"
---




### 缘起
&ensp;&ensp;&ensp;
当我们去运行一个程序的时候， 哪怕是一个简单的helloworld.c程序。 操作系统在执行的过程中会花费大量的时间将信息从一个地方(比如说磁盘)移动到另一个地方(比如说主存)。  
&ensp;&ensp;&ensp;
那么， 从一个程序员的角度来说(a programmer's perspective), 这些复制移动的过程就是程序运行的开销。   
&ensp;&ensp;&ensp;
于是就产生了一个目标：就是使这些复制操作尽可能快的完成。(基于笔者有限的知识， 产生了一个问题， 是否存在这样的一个目标， 不需要复制和移动？)  

### 一个原理  
&ensp;&ensp;&ensp;
根据机械原理， 较大的存储设备要比那些较小的存储设备运行得慢， 并且快速设备的造价远高于同类的低速设备。(咱也不懂机械,既然是原理,用就行了)  

### 一个差异
&ensp;&ensp;&ensp;
处理器的运行速度远高于主存的运行速度， 并且加快处理器的运行速度比加快主存的运行速度要容易，便宜得多。
### 高速缓存存储器
&ensp;&ensp;&ensp;
那么系统设计者就采用了更小也就更快的存储设备 ——— "高速缓存寄存器"(cache memory)。
这种cache起到一个"暂时集结区域"作用。  
&ensp;&ensp;&ensp;
高速缓存是用一种叫做*静态随机访问存储器(SRAM)*的硬件技术实现的。  
&ensp;&ensp;&ensp;
那么我们回到开头， 从一个程序员的角度来说,意识到高速缓存存储器存在的应用程序员能够利用高速缓存将程序的性能提高一个数量级。(什么情况下用， 怎么用，需要进一步学习接触啊)

存储器层次结构——"存储器层次结构的主要思想是上一层的存储器作为低一层存储器的**高速缓存**"
---
&ensp;&ensp;&ensp;
在如下图所示的存储器层次结构中，从上至下， 设备访问速度**越来越慢**， 容量**越来越大**, 每字节的造价也**越来越便宜**。  

![avatar](https://github.com/MuXTing/MuXTing.github.io/blob/master/pic/ComputerSystem/Figure1.9.png)

&ensp;&ensp;&ensp;
可以看到， 存储器层次结构的主要思想是上一层的存储器作为低一层存储器的**高速缓存**。寄存器文件是L1的高速缓存， L1是L2的高速缓存...依次往下。 倘若说上述有点抽象的话， 我来看这样的两句话：  
>"主存是磁盘的高速缓存"  
"在某些具有分布式文件系统的网络系统中， 本地磁盘就是存储在其他系统中磁盘上的数据的高速缓存"  

我们在来回顾另一句话：  
>"通过让高速缓存里存放可能经常访问的数据， 大部分的内存操作都能在快速的高速缓存中完成"


总结
---
总而言之，就是CPU处理器和主存的运行速度上存在差异， 处理器在主存中复制或者移动的过程中会有开销， 那么系统设计者就要想方设法地减少这些开销。 但是呢，提高处理器的运行速度比提高内存的运行速度要来的更简单，划算。为了解决这个问题，通常使用高速缓存来作为一种*暂时的集结区域*，高速缓存的存取运行速度介于CPU和主存之间。系统会将一些CPU在近几个时间段经常访问的内容存入高速缓冲，当CPU需要使用数据时，先在高速缓存中找，如果找到，就不必访问内存了，找不到时，再找内存，这样就在一定程度上缓解了由于主存速度低造成的CPU处理器“停工待料”的情况。 

疑问
---
1. 高速缓存越大越好吗  
我自然而然的会产生一个想法， 把高速存储器造的大一点不就更好了吗。也就是说对高速存储器的物理本质产生了疑惑。 根据那条机械原理， 到底是"容量变大了， 速度就会下降"还是说"造价成本问题"导致了不能无限制扩大高速存储器。 但是根据L1，L2,L3高速缓存这种分层设计来看， 应该是前一个原因。 归根到底也就是缓存技术和内存技术的差异是什么。 

参考资料
---
《深入理解计算机系统》